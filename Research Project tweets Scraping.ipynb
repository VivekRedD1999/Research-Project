{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4a92da74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Twitter HashTag to search for\n",
      "useconomy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "import datetime\n",
    "def scrape(words, numtweet):       \n",
    "        tweets = tweepy.Cursor(api.search_tweets,\n",
    "                               words, lang=\"en\",\n",
    "                               tweet_mode='extended').items(numtweet)\n",
    "        list_tweets = [tweet for tweet in tweets]\n",
    "        i = 1\n",
    "        tweets=[] \n",
    "        date = []\n",
    "        for tweet in list_tweets:\n",
    "                hashtags = tweet.entities['hashtags']\n",
    "                try:\n",
    "                        text = tweet.retweeted_status.full_text\n",
    "                except AttributeError:\n",
    "                        text = tweet.full_text\n",
    "                hashtext = list()\n",
    "                tweets.append(text)\n",
    "                date.append(tweet.created_at)\n",
    "                i = i+1        \n",
    "        return tweets, date\n",
    "        \n",
    " \n",
    "\n",
    "consumer_key = \"jGFiVO9ZIq4NIVXb5Fo9uuC7Y\" \n",
    "consumer_secret = \"y9HR9v7m6WNR4lFIsaPvpvMAGJrwwjsTuDYw48C8J86PwxCrvR\"\n",
    "access_key = \"1573820904701837313-0XTY2xYXQg7YUo3XWLbRvR6qVrqorF\"\n",
    "access_secret = \"DFajYKkXIEbeJQUtc416iVKdhJk18jFtgmLBek6TIWLzp\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "api = tweepy.API(auth)\n",
    " \n",
    "      \n",
    "print(\"Enter Twitter HashTag to search for\")\n",
    "words = input()\n",
    "        \n",
    "numtweet = 2000\n",
    "tweets=scrape(words, numtweet)\n",
    "d = {'Tweets': tweets[0], 'date': tweets[1]}\n",
    "df=pd.DataFrame(data=d)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0630586",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'C:\\Users\\Vivek\\OneDrive\\Desktop\\Google_tweets_8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2671261b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A new Gallup poll released last week found tha...</td>\n",
       "      <td>2023-04-10 17:30:10+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‚ÄúUnder executive order of the President, all p...</td>\n",
       "      <td>2023-04-10 17:09:44+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‚ÄúUnder executive order of the President, all p...</td>\n",
       "      <td>2023-04-10 16:07:59+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‚ÄúUnder executive order of the President, all p...</td>\n",
       "      <td>2023-04-10 16:05:18+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Average hourly #earnings rose 0.3%, pushing th...</td>\n",
       "      <td>2023-04-10 14:12:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>EXPOSED: THE ‚Äú$ECRETS OF THE TEMPLE‚Äù\\n#federal...</td>\n",
       "      <td>2023-04-01 17:14:41+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>üá∫üá∏ GDP\\n\\nThe GDPNow model estimate for US rea...</td>\n",
       "      <td>2023-04-01 16:54:19+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>üá∫üá∏ GDP\\n\\nThe GDPNow model estimate for US rea...</td>\n",
       "      <td>2023-04-01 16:05:28+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>EXPOSED: THE ‚Äú$ECRETS OF THE TEMPLE‚Äù\\n#federal...</td>\n",
       "      <td>2023-04-01 15:41:51+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>Sales Managers Prices Charged Index for Americ...</td>\n",
       "      <td>2023-04-01 15:24:13+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>278 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Tweets  \\\n",
       "0    A new Gallup poll released last week found tha...   \n",
       "1    ‚ÄúUnder executive order of the President, all p...   \n",
       "2    ‚ÄúUnder executive order of the President, all p...   \n",
       "3    ‚ÄúUnder executive order of the President, all p...   \n",
       "4    Average hourly #earnings rose 0.3%, pushing th...   \n",
       "..                                                 ...   \n",
       "273  EXPOSED: THE ‚Äú$ECRETS OF THE TEMPLE‚Äù\\n#federal...   \n",
       "274  üá∫üá∏ GDP\\n\\nThe GDPNow model estimate for US rea...   \n",
       "275  üá∫üá∏ GDP\\n\\nThe GDPNow model estimate for US rea...   \n",
       "276  EXPOSED: THE ‚Äú$ECRETS OF THE TEMPLE‚Äù\\n#federal...   \n",
       "277  Sales Managers Prices Charged Index for Americ...   \n",
       "\n",
       "                         date  \n",
       "0   2023-04-10 17:30:10+00:00  \n",
       "1   2023-04-10 17:09:44+00:00  \n",
       "2   2023-04-10 16:07:59+00:00  \n",
       "3   2023-04-10 16:05:18+00:00  \n",
       "4   2023-04-10 14:12:00+00:00  \n",
       "..                        ...  \n",
       "273 2023-04-01 17:14:41+00:00  \n",
       "274 2023-04-01 16:54:19+00:00  \n",
       "275 2023-04-01 16:05:28+00:00  \n",
       "276 2023-04-01 15:41:51+00:00  \n",
       "277 2023-04-01 15:24:13+00:00  \n",
       "\n",
       "[278 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "525ffca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "final = pd.read_csv(r\"C:\\Users\\Vivek\\OneDrive\\Desktop\\GURRAM SAI VIVEK REDDY\\Seminar in Research & Research Methodology\\Project CSV file.csv\", encoding = 'utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cbbc76e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@ErikSolheim @Google_12point7 @ShehabBawazeer2...</td>\n",
       "      <td>3/6/2023 12:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AI related Important terms you must know for U...</td>\n",
       "      <td>3/6/2023 12:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INEC chairman has obtained a new citizenship i...</td>\n",
       "      <td>3/6/2023 12:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Technical difficulties delay committee meeting...</td>\n",
       "      <td>3/6/2023 12:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I can't shake the feeling that young people pr...</td>\n",
       "      <td>3/6/2023 12:41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets            date\n",
       "0  @ErikSolheim @Google_12point7 @ShehabBawazeer2...  3/6/2023 12:41\n",
       "1  AI related Important terms you must know for U...  3/6/2023 12:41\n",
       "2  INEC chairman has obtained a new citizenship i...  3/6/2023 12:41\n",
       "3  Technical difficulties delay committee meeting...  3/6/2023 12:41\n",
       "4  I can't shake the feeling that young people pr...  3/6/2023 12:41"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a01813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "rev = []\n",
    "for i in final['Tweets']:\n",
    "  s = str(i)\n",
    "  x = s.replace(s[:37],\"\").replace(\"<br/><br/>\",\"\").replace(\"</div>\", \"\").replace(\"\\n\", \" \")\n",
    "  rev.append(x.lower())\n",
    "\n",
    "\n",
    "\n",
    "def Punctuation(rev):\n",
    "    punctuation = string.punctuation\n",
    "    lis = []\n",
    "    for sentence in rev:\n",
    "      se=[]\n",
    "      se.clear()\n",
    "      for j in sentence:\n",
    "        #print(j)\n",
    "        if j in punctuation:\n",
    "          se.append(\"\")        \n",
    "        else:\n",
    "          se.append(j)  \n",
    "      lis.append(\"\".join(se).replace(\"i \", \"\"))\n",
    "      \n",
    "       \n",
    "    return lis\n",
    "      \n",
    "def convert_sentence(rev):\n",
    "  reviews=[]\n",
    "  for i in rev:\n",
    "    review.append(i)\n",
    "  return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd6eff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'Tweets': Punctuation(rev)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "831000e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(r'C:\\Users\\Vivek\\OneDrive\\Desktop\\Recession.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b98fb2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Tweet Date\"] = final[\"date\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28591ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Vivek\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Vivek\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Vivek\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Vivek\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('omw-1.4')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "nltk.download('stopwords')\n",
    "stop=set(stopwords.words('english'))\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "def Tokenize(rev):\n",
    "    reviews=[]\n",
    "    for i in rev:\n",
    "        nltk_tokens = nltk.word_tokenize(i)\n",
    "        reviews.append(nltk_tokens)\n",
    "    return reviews\n",
    "\n",
    "def Stemming_Lemmetize(rev):\n",
    "    lem_reviews = []\n",
    "    for i in rev:\n",
    "        len_sen=[]\n",
    "        for j in i:\n",
    "            len_sen.append(ps.stem(lemmatizer.lemmatize(j)))\n",
    "    lem_reviews.append(len_sen)\n",
    "    return lem_reviews\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop=set(stopwords.words('english'))\n",
    "def stop_words(sl):\n",
    "    \n",
    "    stop = set(stopwords.words('english'))\n",
    "    b=[]\n",
    "    for sen in x:\n",
    "        a=[]\n",
    "        for i in sen:\n",
    "            if i in stop or len(i)==1:\n",
    "                continue\n",
    "            else:\n",
    "                a.append(i)\n",
    "    b.append(a)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d58bdef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bawazeer2 china4tech it will take a lot of hum...</td>\n",
       "      <td>[ErikSolheim, It, take, lot, humility, side, A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>now for upsc prelims  google and just understa...</td>\n",
       "      <td>[AI, related, Important, terms, must, know, UP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zenship in a country called latvia  he will be...</td>\n",
       "      <td>[INEC, chairman, obtained, new, citizenship, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e meeting that google exec was set to attend  ...</td>\n",
       "      <td>[Technical, difficulties, delay, committee, me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>people probably dont care at all about convers...</td>\n",
       "      <td>[ca, n't, shake, feeling, young, people, proba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7 üëâhttpstcomyuvmav4cz   win from the üí∞ of 500...</td>\n",
       "      <td>[Join, MVPTradersLeague, AMA, Mar, üëâhttps, Win...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rally your friends to join the blockchainspac...</td>\n",
       "      <td>[Got, takes, become, legend, Rally, friends, j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ming mints in 30 days üëæü§Ø   want a chance to be...</td>\n",
       "      <td>[Wen, WL, We, 're, launching, FREE, gaming, mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>icipants will get 10 each worth data tokenüî•  c...</td>\n",
       "      <td>[Streamr, Network, The, first, participants, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ber uoftcpe hosted a climate economy summit on...</td>\n",
       "      <td>[UofT, bound, Big, Oil, In, November, UofT_CPE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets  \\\n",
       "0  bawazeer2 china4tech it will take a lot of hum...   \n",
       "1  now for upsc prelims  google and just understa...   \n",
       "2  zenship in a country called latvia  he will be...   \n",
       "3  e meeting that google exec was set to attend  ...   \n",
       "4  people probably dont care at all about convers...   \n",
       "5   7 üëâhttpstcomyuvmav4cz   win from the üí∞ of 500...   \n",
       "6   rally your friends to join the blockchainspac...   \n",
       "7  ming mints in 30 days üëæü§Ø   want a chance to be...   \n",
       "8  icipants will get 10 each worth data tokenüî•  c...   \n",
       "9  ber uoftcpe hosted a climate economy summit on...   \n",
       "\n",
       "                                      cleaned_tweets  \n",
       "0  [ErikSolheim, It, take, lot, humility, side, A...  \n",
       "1  [AI, related, Important, terms, must, know, UP...  \n",
       "2  [INEC, chairman, obtained, new, citizenship, c...  \n",
       "3  [Technical, difficulties, delay, committee, me...  \n",
       "4  [ca, n't, shake, feeling, young, people, proba...  \n",
       "5  [Join, MVPTradersLeague, AMA, Mar, üëâhttps, Win...  \n",
       "6  [Got, takes, become, legend, Rally, friends, j...  \n",
       "7  [Wen, WL, We, 're, launching, FREE, gaming, mi...  \n",
       "8  [Streamr, Network, The, first, participants, g...  \n",
       "9  [UofT, bound, Big, Oil, In, November, UofT_CPE...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#refined_tweets = Stemming_Lemmetize(stop_words(Tokenize(data[\"Tweets\"])))\n",
    "import re\n",
    "x=Tokenize(final[\"Tweets\"])\n",
    "b=[]\n",
    "for sen in x:\n",
    "    a=[]\n",
    "    for i in sen:\n",
    "        if i in stop or len(i)==1 or i[0:5]==\"https\" or i.isdigit() or re.sub(\"\\S*\\d\\S*\", \"\", i)==\"\":\n",
    "            continue\n",
    "        else:\n",
    "            a.append(i)\n",
    "    b.append(a)\n",
    "    \n",
    "data['cleaned_tweets'] = b\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e03a9af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1        False\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "         ...  \n",
       "10537     True\n",
       "10538     True\n",
       "10539    False\n",
       "10540     True\n",
       "10541    False\n",
       "Name: Tweets, Length: 10542, dtype: bool"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "data['Tweets'].duplicated()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "26029a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We',\n",
       " 'seeing',\n",
       " 'outflows',\n",
       " 'EM',\n",
       " 'nothing',\n",
       " 'remotely',\n",
       " 'qualifies',\n",
       " 'exodus',\n",
       " 'Instead',\n",
       " 'price',\n",
       " 'action',\n",
       " 'EM',\n",
       " 'looks',\n",
       " 'like',\n",
       " 'markets',\n",
       " 'giving',\n",
       " 'LatAm',\n",
       " 'theme',\n",
       " 'rotating',\n",
       " 'towards',\n",
       " 'Asia',\n",
       " 'This',\n",
       " 'rotation',\n",
       " 'reflection',\n",
       " 'rising',\n",
       " 'recession',\n",
       " 'risk',\n",
       " 'markets',\n",
       " 'see',\n",
       " 'US',\n",
       " '...']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[10537]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e711054a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8816"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.index(b[10537])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b8275d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "      <th>Tweet Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bawazeer2 china4tech it will take a lot of hum...</td>\n",
       "      <td>[ErikSolheim, It, take, lot, humility, side, A...</td>\n",
       "      <td>3/6/2023 12:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>now for upsc prelims  google and just understa...</td>\n",
       "      <td>[AI, related, Important, terms, must, know, UP...</td>\n",
       "      <td>3/6/2023 12:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zenship in a country called latvia  he will be...</td>\n",
       "      <td>[INEC, chairman, obtained, new, citizenship, c...</td>\n",
       "      <td>3/6/2023 12:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e meeting that google exec was set to attend  ...</td>\n",
       "      <td>[Technical, difficulties, delay, committee, me...</td>\n",
       "      <td>3/6/2023 12:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>people probably dont care at all about convers...</td>\n",
       "      <td>[ca, n't, shake, feeling, young, people, proba...</td>\n",
       "      <td>3/6/2023 12:41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Tweets  \\\n",
       "0  bawazeer2 china4tech it will take a lot of hum...   \n",
       "1  now for upsc prelims  google and just understa...   \n",
       "2  zenship in a country called latvia  he will be...   \n",
       "3  e meeting that google exec was set to attend  ...   \n",
       "4  people probably dont care at all about convers...   \n",
       "\n",
       "                                      cleaned_tweets      Tweet Date  \n",
       "0  [ErikSolheim, It, take, lot, humility, side, A...  3/6/2023 12:41  \n",
       "1  [AI, related, Important, terms, must, know, UP...  3/6/2023 12:41  \n",
       "2  [INEC, chairman, obtained, new, citizenship, c...  3/6/2023 12:41  \n",
       "3  [Technical, difficulties, delay, committee, me...  3/6/2023 12:41  \n",
       "4  [ca, n't, shake, feeling, young, people, proba...  3/6/2023 12:41  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b1be0714",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(r'C:\\Users\\Vivek\\OneDrive\\Desktop\\cleaned_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23819267",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
